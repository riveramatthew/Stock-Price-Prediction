# Stock Price Prediction - Data Exploration and EDA
# This notebook explores historical stock data and prepares it for modeling

# Import Libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import yfinance as yf
from datetime import datetime, timedelta
import warnings
warnings.filterwarnings('ignore')

# Set visualization style
sns.set_style("whitegrid")
plt.rcParams['figure.figsize'] = (14, 6)

print("Libraries imported successfully!")

# ============================================================================
# SECTION 1: DATA COLLECTION
# ============================================================================

# Define stocks to analyze
tickers = ['AAPL', 'GOOGL', 'MSFT', 'TSLA', 'AMZN']
start_date = '2020-01-01'
end_date = '2024-10-01'

print(f"\nDownloading data for {len(tickers)} stocks...")
print(f"Period: {start_date} to {end_date}")

# Download data
data = yf.download(tickers, start=start_date, end=end_date, group_by='ticker')

print(f"\nâœ“ Data downloaded successfully!")
print(f"Shape: {data.shape}")
print(f"Date range: {data.index[0]} to {data.index[-1]}")
print(f"Total trading days: {len(data)}")

# ============================================================================
# SECTION 2: DATA OVERVIEW
# ============================================================================

print("\n" + "="*70)
print("DATA OVERVIEW")
print("="*70)

# Check for missing values
print("\nMissing values per ticker:")
for ticker in tickers:
    missing = data[ticker].isnull().sum().sum()
    total = len(data[ticker]) * len(data[ticker].columns)
    print(f"{ticker}: {missing} ({missing/total*100:.2f}%)")

# Basic statistics for each stock
print("\n" + "-"*70)
print("ADJUSTED CLOSE PRICE STATISTICS")
print("-"*70)

stats_df = pd.DataFrame()
for ticker in tickers:
    stats = {
        'Ticker': ticker,
        'Mean': data[ticker]['Adj Close'].mean(),
        'Median': data[ticker]['Adj Close'].median(),
        'Std': data[ticker]['Adj Close'].std(),
        'Min': data[ticker]['Adj Close'].min(),
        'Max': data[ticker]['Adj Close'].max(),
        'Start_Price': data[ticker]['Adj Close'].iloc[0],
        'End_Price': data[ticker]['Adj Close'].iloc[-1],
        'Total_Return': ((data[ticker]['Adj Close'].iloc[-1] / data[ticker]['Adj Close'].iloc[0]) - 1) * 100
    }
    stats_df = pd.concat([stats_df, pd.DataFrame([stats])], ignore_index=True)

print(stats_df.to_string(index=False))

# ============================================================================
# SECTION 3: VISUALIZATIONS
# ============================================================================

# Plot 1: Price Evolution
print("\nðŸ“Š Generating visualizations...")

fig, axes = plt.subplots(len(tickers), 1, figsize=(14, 3*len(tickers)))

for idx, ticker in enumerate(tickers):
    ax = axes[idx] if len(tickers) > 1 else axes
    
    # Plot Adj Close
    ax.plot(data.index, data[ticker]['Adj Close'], label='Adj Close', linewidth=2)
    
    # Add 50-day and 200-day moving averages
    ma50 = data[ticker]['Adj Close'].rolling(window=50).mean()
    ma200 = data[ticker]['Adj Close'].rolling(window=200).mean()
    
    ax.plot(data.index, ma50, label='50-day MA', alpha=0.7, linewidth=1.5)
    ax.plot(data.index, ma200, label='200-day MA', alpha=0.7, linewidth=1.5)
    
    ax.set_title(f'{ticker} Stock Price Evolution', fontsize=12, fontweight='bold')
    ax.set_xlabel('Date')
    ax.set_ylabel('Price ($)')
    ax.legend(loc='best')
    ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('reports/figures/price_evolution.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 2: Daily Returns Distribution
fig, axes = plt.subplots(2, 3, figsize=(16, 10))
axes = axes.flatten()

for idx, ticker in enumerate(tickers):
    daily_returns = data[ticker]['Adj Close'].pct_change().dropna()
    
    axes[idx].hist(daily_returns, bins=50, alpha=0.7, color='steelblue', edgecolor='black')
    axes[idx].axvline(daily_returns.mean(), color='red', linestyle='--', linewidth=2, label=f'Mean: {daily_returns.mean():.4f}')
    axes[idx].set_title(f'{ticker} Daily Returns Distribution', fontweight='bold')
    axes[idx].set_xlabel('Daily Return')
    axes[idx].set_ylabel('Frequency')
    axes[idx].legend()
    axes[idx].grid(True, alpha=0.3)
    
    # Add statistics
    axes[idx].text(0.02, 0.98, f'Std: {daily_returns.std():.4f}\nSkew: {daily_returns.skew():.2f}',
                  transform=axes[idx].transAxes, verticalalignment='top',
                  bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))

# Remove extra subplot
if len(tickers) < 6:
    fig.delaxes(axes[-1])

plt.tight_layout()
plt.savefig('reports/figures/returns_distribution.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 3: Volume Analysis
fig, ax = plt.subplots(figsize=(14, 6))

for ticker in tickers:
    volume_ma = data[ticker]['Volume'].rolling(window=20).mean()
    ax.plot(data.index, volume_ma, label=ticker, linewidth=2, alpha=0.7)

ax.set_title('20-Day Moving Average Trading Volume', fontsize=14, fontweight='bold')
ax.set_xlabel('Date', fontsize=12)
ax.set_ylabel('Volume', fontsize=12)
ax.legend(fontsize=10)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('reports/figures/volume_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Plot 4: Correlation Heatmap
print("\nðŸ“Š Analyzing correlations...")

# Create a DataFrame of adjusted close prices
price_data = pd.DataFrame()
for ticker in tickers:
    price_data[ticker] = data[ticker]['Adj Close']

# Calculate correlation matrix
correlation_matrix = price_data.corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, fmt='.3f', cmap='coolwarm', 
            square=True, linewidths=1, cbar_kws={"shrink": 0.8})
plt.title('Stock Price Correlation Matrix', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.savefig('reports/figures/correlation_heatmap.png', dpi=300, bbox_inches='tight')
plt.show()

# ============================================================================
# SECTION 4: VOLATILITY ANALYSIS
# ============================================================================

print("\n" + "="*70)
print("VOLATILITY ANALYSIS")
print("="*70)

# Calculate rolling volatility (30-day standard deviation of returns)
volatility_df = pd.DataFrame()

for ticker in tickers:
    returns = data[ticker]['Adj Close'].pct_change()
    volatility = returns.rolling(window=30).std() * np.sqrt(252)  # Annualized
    volatility_df[ticker] = volatility

# Plot volatility
fig, ax = plt.subplots(figsize=(14, 6))

for ticker in tickers:
    ax.plot(volatility_df.index, volatility_df[ticker], label=ticker, linewidth=2, alpha=0.7)

ax.set_title('30-Day Rolling Volatility (Annualized)', fontsize=14, fontweight='bold')
ax.set_xlabel('Date', fontsize=12)
ax.set_ylabel('Volatility', fontsize=12)
ax.legend(fontsize=10)
ax.grid(True, alpha=0.3)

plt.tight_layout()
plt.savefig('reports/figures/volatility_analysis.png', dpi=300, bbox_inches='tight')
plt.show()

# Print volatility statistics
print("\nVolatility Statistics (Last 30 days):")
recent_volatility = volatility_df.tail(30).mean()
for ticker in tickers:
    print(f"{ticker}: {recent_volatility[ticker]:.4f}")

# ============================================================================
# SECTION 5: KEY INSIGHTS
# ============================================================================

print("\n" + "="*70)
print("KEY INSIGHTS FROM DATA EXPLORATION")
print("="*70)

insights = []

# 1. Best performing stock
best_performer = stats_df.loc[stats_df['Total_Return'].idxmax()]
insights.append(f"1. Best Performer: {best_performer['Ticker']} with {best_performer['Total_Return']:.2f}% return")

# 2. Most volatile stock
most_volatile = recent_volatility.idxmax()
insights.append(f"2. Most Volatile: {most_volatile} with volatility of {recent_volatility[most_volatile]:.4f}")

# 3. Highest correlation pair
corr_values = []
for i in range(len(tickers)):
    for j in range(i+1, len(tickers)):
        corr_values.append((tickers[i], tickers[j], correlation_matrix.iloc[i, j]))
highest_corr = max(corr_values, key=lambda x: x[2])
insights.append(f"3. Highest Correlation: {highest_corr[0]}-{highest_corr[1]} with {highest_corr[2]:.3f}")

# 4. Data quality
total_missing = sum([data[ticker].isnull().sum().sum() for ticker in tickers])
insights.append(f"4. Data Quality: {total_missing} missing values across all stocks")

# 5. Trading days
insights.append(f"5. Total Trading Days: {len(data)} days over ~{(pd.to_datetime(end_date) - pd.to_datetime(start_date)).days} calendar days")

for insight in insights:
    print(f"\n{insight}")

print("\n" + "="*70)
print("âœ“ Data exploration complete!")
print("âœ“ All visualizations saved to reports/figures/")
print("="*70)

# ============================================================================
# SECTION 6: SAVE PROCESSED DATA
# ============================================================================

# Save the data for use in modeling
print("\nðŸ’¾ Saving processed data...")
data.to_csv('data/processed/stock_data_processed.csv')
stats_df.to_csv('data/processed/stock_statistics.csv', index=False)
correlation_matrix.to_csv('data/processed/correlation_matrix.csv')

print("âœ“ Data saved successfully!")
print("\nNext steps:")
print("  1. Run feature engineering notebook (02_feature_engineering.ipynb)")
print("  2. Train baseline models (03_model_comparison.ipynb)")
print("  3. Evaluate and refine (04_final_evaluation.ipynb)")
